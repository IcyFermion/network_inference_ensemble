{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from tqdm import tqdm \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from config import base_algo_print_names, base_algo_symbols, ensemble_algo_print_names, cv_split_sets\n",
    "\n",
    "# styling:\n",
    "import seaborn as sns\n",
    "plt.style.use(['ggplot'])\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global variables\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "algo_names = base_algo_print_names\n",
    "algos = base_algo_symbols\n",
    "# ensemble_algo_names = [\"OutPredict\", 'Inferelator', 'GRNBoost2', 'Genie3', 'PIDC', 'LEAP', 'SCODE', 'SCRIBE', 'SINCERITIES', 'PPCOR', 'Ensemble A', 'Ensemble B', 'Ensemble C', 'Ensemble D']\n",
    "ensemble_algo_names = ensemble_algo_print_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some filtering on the network, only validated tfs are kept\n",
    "set_dir = 'tf_split_sets/42/'\n",
    "train_df = pd.read_csv(set_dir+'train_by_tf_genes.csv', index_col=0)\n",
    "test_df = pd.read_csv(set_dir+'test_by_tf_genes.csv', index_col=0)\n",
    "# op_mat = pd.read_csv(set_dir+'Matrix_TF_gene_best_model.tsv', sep='\\t', index_col=0)\n",
    "# inf_mat = pd.read_csv(set_dir+'inf_matrix_tf_{}.tsv'.format(set_serial), sep='\\t', index_col=0)\n",
    "\n",
    "gs_tf_set = set()\n",
    "for index, row in test_df.iterrows():\n",
    "    edge_name = index\n",
    "    regulator_name, target_name = edge_name.split('>')\n",
    "    if (int(row['edge_exist']) == 1):\n",
    "        gs_tf_set.add(regulator_name)\n",
    "for index, row in train_df.iterrows():\n",
    "    edge_name = index\n",
    "    regulator_name, target_name = edge_name.split('>')\n",
    "    if (int(row['edge_exist']) == 1):\n",
    "        gs_tf_set.add(regulator_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# staking run on a particular split and a particular ensemble classifier\n",
    "def evaluate_run(set_serial, clf):\n",
    "    set_dir = 'tf_split_sets/{}/'.format(set_serial)\n",
    "    train_df = pd.read_csv(set_dir+'train_by_tf_genes.csv', index_col=0)\n",
    "    test_df = pd.read_csv(set_dir+'test_by_tf_genes.csv', index_col=0)\n",
    "    \n",
    "    to_drop_list = []\n",
    "    for index, row in test_df.iterrows():\n",
    "        edge_name = index\n",
    "        regulator_name, target_name = edge_name.split('>')\n",
    "        if (regulator_name not in gs_tf_set):\n",
    "            to_drop_list.append(index)\n",
    "    test_df = test_df.drop(to_drop_list)\n",
    "    to_drop_list = []\n",
    "    for index, row in train_df.iterrows():\n",
    "        edge_name = index\n",
    "        regulator_name, target_name = edge_name.split('>')\n",
    "        if (regulator_name not in gs_tf_set):\n",
    "            to_drop_list.append(index)\n",
    "    train_df = train_df.drop(to_drop_list)\n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = train_df[['op', 'inf', 'grnboost', 'genie', 'pidc', 'leap', 'scode', 'scribe', 'sincerities', 'ppcor']].values\n",
    "    X_train = min_max_scaler.fit_transform(X_train)\n",
    "    y_train = train_df['edge_exist']\n",
    "    X_test = test_df[['op', 'inf', 'grnboost', 'genie', 'pidc', 'leap', 'scode', 'scribe', 'sincerities', 'ppcor']].values\n",
    "    X_test = min_max_scaler.fit_transform(X_test)\n",
    "    y_test = test_df['edge_exist']\n",
    "    clf.fit(X_train, y_train)\n",
    "    ensemble_pr = precision_recall_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "    X_train = train_df[['op', 'grnboost', 'genie', 'pidc', 'leap', 'sincerities', 'ppcor']].values\n",
    "    X_train = min_max_scaler.fit_transform(X_train)\n",
    "    y_train = train_df['edge_exist']\n",
    "    X_test = test_df[['op', 'grnboost', 'genie', 'pidc', 'leap', 'sincerities', 'ppcor']].values\n",
    "    X_test = min_max_scaler.fit_transform(X_test)\n",
    "    y_test = test_df['edge_exist']\n",
    "    clf.fit(X_train, y_train)\n",
    "    ensemble_pr_less = precision_recall_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "    # X_train = train_df[['op', 'grnboost', 'genie', 'pidc', 'leap', 'sincerities', 'ppcor', 'lagged_cor']].values\n",
    "    # X_train = min_max_scaler.fit_transform(X_train)\n",
    "    # y_train = train_df['edge_exist']\n",
    "    # X_test = test_df[['op', 'grnboost', 'genie', 'pidc', 'leap', 'sincerities', 'ppcor', 'lagged_cor']].values\n",
    "    # X_test = min_max_scaler.fit_transform(X_test)\n",
    "    # y_test = test_df['edge_exist']\n",
    "    # clf.fit(X_train, y_train)\n",
    "    # ensemble_pr_less_priors = precision_recall_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "    X_train = train_df[['op', 'inf', 'grnboost', 'genie', 'pidc', 'leap', 'scode', 'scribe', 'sincerities', 'ppcor', 'ss_cor', 'lagged_cor']].values\n",
    "    X_train = min_max_scaler.fit_transform(X_train)\n",
    "    y_train = train_df['edge_exist']\n",
    "    X_test = test_df[['op', 'inf', 'grnboost', 'genie', 'pidc', 'leap', 'scode', 'scribe', 'sincerities', 'ppcor', 'ss_cor', 'lagged_cor']].values\n",
    "    X_test = min_max_scaler.fit_transform(X_test)\n",
    "    y_test = test_df['edge_exist']\n",
    "    # clf.fit(X_train, y_train)\n",
    "    # ensemble_pr_priors = precision_recall_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "    rand_aupr = y_test.sum()/len(y_test)\n",
    "    algo_names = [\"OutPredict\", 'Inferelator', 'GRNBoost2', 'Genie3', 'PIDC', 'LEAP', 'SCODE', 'SCRIBE', 'SINCERITIES', 'PPCOR']\n",
    "    pr_list = []\n",
    "    pr_scores = []\n",
    "    pr_ratios = []\n",
    "    for i in range(10):\n",
    "        pr = precision_recall_curve(y_test, X_test[:,i])\n",
    "        pr_list.append(pr)\n",
    "        pr_scores.append(auc(pr[1], pr[0]))\n",
    "        pr_ratios.append(auc(pr[1], pr[0])/rand_aupr)\n",
    "    rankings = np.argsort(np.array(pr_scores))[::-1]\n",
    "\n",
    "    pr_ratios.append(auc(ensemble_pr[1], ensemble_pr[0])/rand_aupr)\n",
    "    pr_ratios.append(auc(ensemble_pr_less[1], ensemble_pr_less[0])/rand_aupr)\n",
    "    # pr_ratios.append(auc(ensemble_pr_less_priors[1], ensemble_pr_less_priors[0])/rand_aupr)\n",
    "    # pr_ratios.append(auc(ensemble_pr_priors[1], ensemble_pr_priors[0])/rand_aupr)\n",
    "    aupr_df.loc[len(aupr_df.index)] = pr_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:49<00:00,  8.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# stacking with Naive Bayes with Gaussian kernel\n",
    "clf = GaussianNB(var_smoothing=2.848035868435805e-09)\n",
    "aupr_df = pd.DataFrame(columns=ensemble_algo_names)\n",
    "for i in tqdm(cv_split_sets):\n",
    "    evaluate_run(i, clf)\n",
    "aupr_df.to_csv('arabidopsis_auprc_nb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [06:01<00:00, 18.10s/it]\n"
     ]
    }
   ],
   "source": [
    "# stacking with random forest\n",
    "clf = RandomForestClassifier(bootstrap=False, max_depth=8, max_features='sqrt', n_estimators=500, n_jobs=-1, random_state=42)\n",
    "aupr_df = pd.DataFrame(columns=ensemble_algo_names)\n",
    "for i in tqdm(cv_split_sets):\n",
    "    evaluate_run(i, clf)\n",
    "aupr_df.to_csv('arabidopsis_auprc_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:01<00:00,  9.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# stacking with logistic regression\n",
    "clf = LogisticRegression(random_state=42, n_jobs=-1, C=100, penalty='l2',solver='newton-cg')\n",
    "aupr_df = pd.DataFrame(columns=ensemble_algo_names)\n",
    "for i in tqdm(cv_split_sets):\n",
    "    evaluate_run(i, clf)\n",
    "aupr_df.to_csv('arabidopsis_auprc_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking with AB boost\n",
    "clf = AdaBoostClassifier(random_state=42, learning_rate=0.1, n_estimators=100)\n",
    "aupr_df = pd.DataFrame(columns=ensemble_algo_names)\n",
    "for i in tqdm(cv_split_sets):\n",
    "    evaluate_run(i, clf)\n",
    "aupr_df.to_csv('arabidopsis_auprc_ab.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0625736e76ce7a086b05dcdb3b30b057da1874f4b7d94f712ab6b40a66351ac"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
