{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from tqdm import tqdm \n",
    "from sklearn import metrics \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# styling:\n",
    "import seaborn as sns\n",
    "plt.style.use(['ggplot'])\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble data set up\n",
    "# algo_names = ['op', 'inf', 'grnboost', 'genie3', 'grisli', 'grnvbem', 'leap',  'pidc', 'ppcor', 'scode', 'scribe', 'sincerities', 'ss_cor', 'ss_ranked']\n",
    "algo_names = ['op', 'inf', 'grnboost', 'genie3', 'grisli', 'grnvbem', 'leap',  'pidc', 'ppcor', 'scode', 'scribe', 'sincerities', 'ss_cor', 'ss_ranked']\n",
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = pd.read_csv('tf_names.tsv', index_col=0)\n",
    "len(np.array(tf_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_df = pd.read_csv('ensemble.csv')\n",
    "all_data = pd.DataFrame(columns=ensemble_df.columns)\n",
    "\n",
    "tf_set = np.array(tf_df.index)\n",
    "np.random.seed(4)\n",
    "np.random.shuffle(tf_set)\n",
    "train_tf_list = tf_set[:66]\n",
    "test_tf_list = tf_set[66:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dirs = ['./']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_print_names = ['OutPredict', 'Inferelator', 'GRNBoost', 'Genie3', 'GRISLI', 'GRNVBEM', 'LEAP',  'PIDC', 'PPCOR', 'SCODE', 'SCRIBE', 'SINCERITIES']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models = [LogisticRegression(random_state=42, n_jobs=-1), GaussianNB(), SGDClassifier(loss='log', random_state=42, n_jobs=-1), \n",
    "SVC(random_state=42, probability=True), KNeighborsClassifier(), RandomForestClassifier(random_state=42, n_jobs = -1), AdaBoostClassifier(random_state=42),\n",
    "XGBClassifier(random_state=42, n_jobs=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_grid = {\n",
    "    'random_state': [42],\n",
    "    'n_jobs': [-1],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'penalty': ['l2'],\n",
    "    'C': [100, 10, 1.0, 0.1, 0.01]\n",
    "}\n",
    "NB_grid = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "}\n",
    "\n",
    "SGD_grid = {\n",
    "    'random_state': [42],\n",
    "    'n_jobs': [-1],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "    'loss': ['log'], \n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "SVC_grid = {\n",
    "    'random_state': [42],\n",
    "    'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "    'C': [50, 10, 1.0, 0.1, 0.01],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "KNN_grid = {\n",
    "    'n_neighbors': range(1, 21, 2),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "RF_grid = {\n",
    "    'random_state': [42],\n",
    "    'n_jobs': [-1],\n",
    "    'n_estimators': [10, 50, 100, 500],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': range (2, 10, 2),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "AB_grid = {\n",
    "    'random_state': [42],\n",
    "    'n_estimators': [10, 50, 100, 500],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "XGB_grid = {\n",
    "    'random_state': [42],\n",
    "    'n_jobs': [-1],\n",
    "    'max_depth': range (2, 10, 2),\n",
    "    'n_estimators': [10, 50, 100, 500],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "    }\n",
    "\n",
    "grid_list = [LR_grid, NB_grid, SGD_grid, SVC_grid, KNN_grid, RF_grid, AB_grid, XGB_grid]\n",
    "\n",
    "ensemble_names = ['LR', 'NB', 'SGD', 'SVM', 'KNN', 'RF', 'AB', 'XGB', 'AVG']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns = algo_print_names + ['Ensemble_LR', 'Ensemble_NB', 'Ensemble_SGD', 'Ensemble_SVM', 'Ensemble_KNN', 'Ensemble_RF', 'Ensemble_AB', 'Ensemble_XGB', 'Ensemble_AVG']\n",
    "df_columns = df_columns + ['best_train_algo', 'best_test_algo', 'best_train_score', 'best_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "algo_names = ['op', 'inf', 'grnboost', 'genie3', 'grisli', 'grnvbem', 'leap',  'pidc', 'ppcor', 'scode', 'scribe']\n",
    "algo_list = algo_print_names\n",
    "algo_list.append('Ensemble')\n",
    "X_train = ensemble_df[algo_names].values \n",
    "y_train = ensemble_df['edge_exist']\n",
    "\n",
    "model = XGBClassifier(random_state=42, n_jobs=-1)\n",
    "grid = XGB_grid\n",
    "name = 'XGB'\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=grid,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = -1,\n",
    "    cv = 5,\n",
    "    verbose=True\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('best parameters for {} ensemble is: '.format(name))\n",
    "print(grid_search.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "algo_names = ['op', 'inf', 'grnboost', 'genie3', 'grisli', 'grnvbem', 'leap',  'pidc', 'ppcor', 'scode', 'scribe']\n",
    "algo_list = algo_print_names\n",
    "algo_list.append('Ensemble')\n",
    "X_train = ensemble_df[algo_names].values \n",
    "y_train = ensemble_df['edge_exist']\n",
    "\n",
    "for model, grid, name in zip(ensemble_models, grid_list, ensemble_names):\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=grid,\n",
    "        scoring = 'roc_auc',\n",
    "        n_jobs = -1,\n",
    "        cv = 5,\n",
    "        verbose=False\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print('best parameters for {} ensemble is: '.format(name))\n",
    "    print(grid_search.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best parameters for LR ensemble is: \n",
    "{'C': 100, 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cg'}\n",
    "best parameters for NB ensemble is: \n",
    "{'var_smoothing': 2.848035868435805e-09}\n",
    "best parameters for SGD ensemble is: \n",
    "{'alpha': 0.1, 'loss': 'log', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 42}\n",
    "best parameters for SVM ensemble is: \n",
    "{'C': 50, 'gamma': 'scale', 'kernel': 'poly', 'random_state': 42}\n",
    "best parameters for KNN ensemble is: \n",
    "{'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'}\n",
    "best parameters for RF ensemble is: \n",
    "{'bootstrap': False, 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 500, 'n_jobs': -1, 'random_state': 42}\n",
    "best parameters for AB ensemble is: \n",
    "{'learning_rate': 0.1, 'n_estimators': 100, 'random_state': 42}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0625736e76ce7a086b05dcdb3b30b057da1874f4b7d94f712ab6b40a66351ac"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
